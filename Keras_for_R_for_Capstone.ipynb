{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Keras for R for Capstone.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMMfCPHBd04mEh/gitgCO7e",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "R",
      "name": "ir"
    },
    "language_info": {
      "name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vsnupoudel/data-science-capstone-JohnsHopkins/blob/master/Keras_for_R_for_Capstone.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cfHpbP7F0md"
      },
      "source": [
        "## After setting working directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "0D6gH9nuF_-a",
        "outputId": "ddd01b3d-421d-4f2b-eb18-41adaa42531a"
      },
      "source": [
        "getwd()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] \"/content\""
            ],
            "text/latex": "'/content'",
            "text/markdown": "'/content'",
            "text/html": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8YLhC_RwMAO",
        "outputId": "041ee18b-06c1-421a-f88d-eabc42e3a275"
      },
      "source": [
        "install.packages( c( \"tm\",\"ngram\",\"dplyr\",\"tidyr\",\"keras\",\"data.table\",\"stringr\") )\n",
        "x <- c( \"tm\", \"ngram\", \"dplyr\", \"tidyr\", \"keras\", \"data.table\")\n",
        "z = lapply(x, require, character.only = TRUE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Installing packages into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependencies ‘png’, ‘config’, ‘NLP’, ‘slam’, ‘reticulate’, ‘tensorflow’, ‘tfruns’, ‘zeallot’\n",
            "\n",
            "\n",
            "Loading required package: tm\n",
            "\n",
            "Loading required package: NLP\n",
            "\n",
            "Loading required package: ngram\n",
            "\n",
            "Loading required package: dplyr\n",
            "\n",
            "\n",
            "Attaching package: ‘dplyr’\n",
            "\n",
            "\n",
            "The following objects are masked from ‘package:stats’:\n",
            "\n",
            "    filter, lag\n",
            "\n",
            "\n",
            "The following objects are masked from ‘package:base’:\n",
            "\n",
            "    intersect, setdiff, setequal, union\n",
            "\n",
            "\n",
            "Loading required package: tidyr\n",
            "\n",
            "Loading required package: keras\n",
            "\n",
            "Loading required package: data.table\n",
            "\n",
            "\n",
            "Attaching package: ‘data.table’\n",
            "\n",
            "\n",
            "The following objects are masked from ‘package:dplyr’:\n",
            "\n",
            "    between, first, last\n",
            "\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jdwfAqqrA3g"
      },
      "source": [
        "system(\"gdown --id 1hlvOXJqe3fdxjQilNfLRwPud_KWcOVEE -O '/content/en_US.zip' \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKzHv9DkxXHp"
      },
      "source": [
        "unzip(zipfile= '/content/en_US.zip', overwrite = TRUE )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-myLUobHnU-"
      },
      "source": [
        "system(\" gdown --id 1r3MHZdvnlC_BG8z6Jr1td-zJTC2GdqYK -O 'glove.6B.50d.txt'  \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISklhRQgFxJ1",
        "outputId": "4f759eeb-a457-4226-9ebe-b2bc8ac34a16"
      },
      "source": [
        "# # establish connections with three files \n",
        "print( getwd())\n",
        "con3 <- file( '/content/en_US/en_US.twitter.txt', 'r')\n",
        "text3 <- readLines(con3)\n",
        "close(con3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1] \"/content\"\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Warning message in readLines(con3):\n",
            "“line 167155 appears to contain an embedded nul”\n",
            "Warning message in readLines(con3):\n",
            "“line 268547 appears to contain an embedded nul”\n",
            "Warning message in readLines(con3):\n",
            "“line 1274086 appears to contain an embedded nul”\n",
            "Warning message in readLines(con3):\n",
            "“line 1759032 appears to contain an embedded nul”\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZOrFTcVL4Nx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d49ff154-38a8-4fd7-94d1-bd1339f484aa"
      },
      "source": [
        "# # sample 0.01% data\n",
        "sample_index <- sample(seq(text3), 0.01*length(text3))\n",
        "sample_text <- text3[sample_index]\n",
        "\n",
        "dir.create(file.path(\"./sample_text\"))\n",
        "con4 <- file('./sample_text/sampled_text.txt')\n",
        "writeLines(sample_text, con = con4)\n",
        "close(con4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning message in dir.create(file.path(\"./sample_text\")):\n",
            "“'./sample_text' already exists”\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "s-6O2L5Akytl",
        "outputId": "60d5fe47-f37b-48e3-f267-a34a03cf1ec1"
      },
      "source": [
        "length( sample_text )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] 23601"
            ],
            "text/latex": "23601",
            "text/markdown": "23601",
            "text/html": [
              "23601"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2qEAX-to_XX",
        "outputId": "c7651aad-2b81-4b6b-e004-f996511d9a93"
      },
      "source": [
        "# Using the tm library for preprocessing the sample text\n",
        "library(tm)\n",
        "data_folder = DirSource(directory = \"./sample_text\",\n",
        "            encoding = \"UTF-8\",\n",
        "            mode = \"text\")\n",
        "# load the file into Corpus object\n",
        "docs <- SimpleCorpus( data_folder )\n",
        "# Converting to lowercase:\n",
        "docs <- tm_map(docs, tolower)\n",
        "docs <- tm_map(docs, PlainTextDocument)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning message in tm_map.SimpleCorpus(docs, PlainTextDocument):\n",
            "“transformation drops documents”\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "4uIVgGRFpDwx",
        "outputId": "3927ce10-9ae4-40b8-eb0c-bcc1f246bf48"
      },
      "source": [
        "length(docs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] 2"
            ],
            "text/latex": "2",
            "text/markdown": "2",
            "text/html": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "id": "hWIBvzbInbHT",
        "outputId": "f739ef57-a3dc-4d69-842d-ca515428bb39"
      },
      "source": [
        "library(ngram)\n",
        "string <- docs[[1]]$content\n",
        "# trying different libraries\n",
        "# library(tokenizers)\n",
        "# library(word2vec)\n",
        "# string.summary(string)\n",
        "ng <- ngram (string, n=3)\n",
        "# get.phrasetable(ng)\n",
        "# tokens <- tokenize_ngrams(string , n = 3 )\n",
        "\n",
        "# As a data frame\n",
        "df <- data.frame(get.phrasetable(ng))\n",
        "\n",
        "# Put the last word as target\n",
        "library(tidyr)\n",
        "sep<- separate(data = df, col = ngrams , into = c(\"X1\",\"X2\", \"y\")\n",
        "               # ,sep = \"^\\\\w+\\\\s+\"\n",
        "               # , remove=FALSE\n",
        "               )\n",
        "# Xy <- unite(sep , X , c(X1, X2 ), remove=TRUE, sep=\" \")\n",
        "df <- data.frame(sep)\n",
        "remove(sep)\n",
        "head(df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“Expected 3 pieces. Additional pieces discarded in 254102 rows [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, ...].”\n",
            "Warning message:\n",
            "“Expected 3 pieces. Missing pieces filled with `NA` in 124 rows [96, 251, 2453, 5103, 9968, 12925, 13542, 15370, 15508, 18641, 21558, 24558, 26436, 33104, 35278, 38149, 40931, 51012, 54388, 57985, ...].”\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  X1      X2      y     freq prop        \n",
              "1 going   to      be    73   0.0002615916\n",
              "2 thanks  for     the   62   0.0002221736\n",
              "3 looking forward to    59   0.0002114233\n",
              "4 to      be      a     59   0.0002114233\n",
              "5 is      going   to    57   0.0002042564\n",
              "6 have    a       great 55   0.0001970895"
            ],
            "text/latex": "A data.frame: 6 × 5\n\\begin{tabular}{r|lllll}\n  & X1 & X2 & y & freq & prop\\\\\n  & <chr> & <chr> & <chr> & <int> & <dbl>\\\\\n\\hline\n\t1 & going   & to      & be    & 73 & 0.0002615916\\\\\n\t2 & thanks  & for     & the   & 62 & 0.0002221736\\\\\n\t3 & looking & forward & to    & 59 & 0.0002114233\\\\\n\t4 & to      & be      & a     & 59 & 0.0002114233\\\\\n\t5 & is      & going   & to    & 57 & 0.0002042564\\\\\n\t6 & have    & a       & great & 55 & 0.0001970895\\\\\n\\end{tabular}\n",
            "text/markdown": "\nA data.frame: 6 × 5\n\n| <!--/--> | X1 &lt;chr&gt; | X2 &lt;chr&gt; | y &lt;chr&gt; | freq &lt;int&gt; | prop &lt;dbl&gt; |\n|---|---|---|---|---|---|\n| 1 | going   | to      | be    | 73 | 0.0002615916 |\n| 2 | thanks  | for     | the   | 62 | 0.0002221736 |\n| 3 | looking | forward | to    | 59 | 0.0002114233 |\n| 4 | to      | be      | a     | 59 | 0.0002114233 |\n| 5 | is      | going   | to    | 57 | 0.0002042564 |\n| 6 | have    | a       | great | 55 | 0.0001970895 |\n\n",
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A data.frame: 6 × 5</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>X1</th><th scope=col>X2</th><th scope=col>y</th><th scope=col>freq</th><th scope=col>prop</th></tr>\n",
              "\t<tr><th></th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>1</th><td>going  </td><td>to     </td><td>be   </td><td>73</td><td>0.0002615916</td></tr>\n",
              "\t<tr><th scope=row>2</th><td>thanks </td><td>for    </td><td>the  </td><td>62</td><td>0.0002221736</td></tr>\n",
              "\t<tr><th scope=row>3</th><td>looking</td><td>forward</td><td>to   </td><td>59</td><td>0.0002114233</td></tr>\n",
              "\t<tr><th scope=row>4</th><td>to     </td><td>be     </td><td>a    </td><td>59</td><td>0.0002114233</td></tr>\n",
              "\t<tr><th scope=row>5</th><td>is     </td><td>going  </td><td>to   </td><td>57</td><td>0.0002042564</td></tr>\n",
              "\t<tr><th scope=row>6</th><td>have   </td><td>a      </td><td>great</td><td>55</td><td>0.0001970895</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfGi_wHdVFJu"
      },
      "source": [
        "References:\n",
        "\n",
        "[Keras Article](https://keras.rstudio.com/articles/examples/pretrained_word_embeddings.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "5x4FcDYvv8BU",
        "outputId": "4b3f63d2-8e2e-495d-e9ce-348eaae9b7b6"
      },
      "source": [
        "# Try downloading pre-trained word embeddings instead of training new\n",
        "# This example shows how one can quickly load glove vectors\n",
        "# and train a Keras model in R\n",
        "library(keras)\n",
        "library(dplyr)\n",
        "\n",
        "# Load the word embeddings as df \n",
        "# load glove vectors into R\n",
        "vectors = data.table::fread('glove.6B.50d.txt', data.table = F\n",
        "                            ,  encoding = 'UTF-8')\n",
        "colnames(vectors) = c('word',paste('dim',1:50,sep = '_'))\n",
        "\n",
        "vecDf <- as_tibble(vectors)\n",
        "head(vecDf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning message in data.table::fread(\"glove.6B.50d.txt\", data.table = F, encoding = \"UTF-8\"):\n",
            "“Found and resolved improper quoting in first 100 rows. If the fields are not quoted (e.g. field separator does not appear within any field), try quote=\"\" to avoid this warning.”\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  word dim_1    dim_2     dim_3    dim_4     dim_5   dim_6     dim_7   \n",
              "1 the  0.418000  0.249680 -0.41242  0.121700 0.34527 -0.044457 -0.49688\n",
              "2 ,    0.013441  0.236820 -0.16899  0.409510 0.63812  0.477090 -0.42852\n",
              "3 .    0.151640  0.301770 -0.16763  0.176840 0.31719  0.339730 -0.43478\n",
              "4 of   0.708530  0.570880 -0.47160  0.180480 0.54449  0.726030  0.18157\n",
              "5 to   0.680470 -0.039263  0.30186 -0.177920 0.42962  0.032246 -0.41376\n",
              "6 and  0.268180  0.143460 -0.27877  0.016257 0.11384  0.699230 -0.51332\n",
              "  dim_8    dim_9       ⋯ dim_41      dim_42    dim_43    dim_44    dim_45  \n",
              "1 -0.17862 -0.00066023 ⋯ -2.9871e-01 -0.157490 -0.347580 -0.045637 -0.44251\n",
              "2 -0.55641 -0.36400000 ⋯ -8.0262e-02  0.630030  0.321110 -0.467650  0.22786\n",
              "3 -0.31086 -0.44999000 ⋯ -6.3681e-05  0.068987  0.087939 -0.102850 -0.13931\n",
              "4 -0.52393  0.10381000 ⋯ -3.4727e-01  0.284830  0.075693 -0.062178 -0.38988\n",
              "5  0.13228 -0.29847000 ⋯ -9.4375e-02  0.018324  0.210480 -0.030880 -0.19722\n",
              "6 -0.47368 -0.33075000 ⋯ -6.9043e-02  0.368850  0.251680 -0.245170  0.25381\n",
              "  dim_46   dim_47     dim_48    dim_49    dim_50  \n",
              "1 0.187850  0.0027849 -0.184110 -0.115140 -0.78581\n",
              "2 0.360340 -0.3781800 -0.566570  0.044691  0.30392\n",
              "3 0.223140 -0.0808030 -0.356520  0.016413  0.10216\n",
              "4 0.229020 -0.2161700 -0.225620 -0.093918 -0.80375\n",
              "5 0.082279 -0.0943400 -0.073297 -0.064699 -0.26044\n",
              "6 0.136700 -0.3117800 -0.632100 -0.250280 -0.38097"
            ],
            "text/latex": "A tibble: 6 × 51\n\\begin{tabular}{lllllllllllllllllllll}\n word & dim\\_1 & dim\\_2 & dim\\_3 & dim\\_4 & dim\\_5 & dim\\_6 & dim\\_7 & dim\\_8 & dim\\_9 & ⋯ & dim\\_41 & dim\\_42 & dim\\_43 & dim\\_44 & dim\\_45 & dim\\_46 & dim\\_47 & dim\\_48 & dim\\_49 & dim\\_50\\\\\n <chr> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & ⋯ & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n\\hline\n\t the & 0.418000 &  0.249680 & -0.41242 &  0.121700 & 0.34527 & -0.044457 & -0.49688 & -0.17862 & -0.00066023 & ⋯ & -2.9871e-01 & -0.157490 & -0.347580 & -0.045637 & -0.44251 & 0.187850 &  0.0027849 & -0.184110 & -0.115140 & -0.78581\\\\\n\t ,   & 0.013441 &  0.236820 & -0.16899 &  0.409510 & 0.63812 &  0.477090 & -0.42852 & -0.55641 & -0.36400000 & ⋯ & -8.0262e-02 &  0.630030 &  0.321110 & -0.467650 &  0.22786 & 0.360340 & -0.3781800 & -0.566570 &  0.044691 &  0.30392\\\\\n\t .   & 0.151640 &  0.301770 & -0.16763 &  0.176840 & 0.31719 &  0.339730 & -0.43478 & -0.31086 & -0.44999000 & ⋯ & -6.3681e-05 &  0.068987 &  0.087939 & -0.102850 & -0.13931 & 0.223140 & -0.0808030 & -0.356520 &  0.016413 &  0.10216\\\\\n\t of  & 0.708530 &  0.570880 & -0.47160 &  0.180480 & 0.54449 &  0.726030 &  0.18157 & -0.52393 &  0.10381000 & ⋯ & -3.4727e-01 &  0.284830 &  0.075693 & -0.062178 & -0.38988 & 0.229020 & -0.2161700 & -0.225620 & -0.093918 & -0.80375\\\\\n\t to  & 0.680470 & -0.039263 &  0.30186 & -0.177920 & 0.42962 &  0.032246 & -0.41376 &  0.13228 & -0.29847000 & ⋯ & -9.4375e-02 &  0.018324 &  0.210480 & -0.030880 & -0.19722 & 0.082279 & -0.0943400 & -0.073297 & -0.064699 & -0.26044\\\\\n\t and & 0.268180 &  0.143460 & -0.27877 &  0.016257 & 0.11384 &  0.699230 & -0.51332 & -0.47368 & -0.33075000 & ⋯ & -6.9043e-02 &  0.368850 &  0.251680 & -0.245170 &  0.25381 & 0.136700 & -0.3117800 & -0.632100 & -0.250280 & -0.38097\\\\\n\\end{tabular}\n",
            "text/markdown": "\nA tibble: 6 × 51\n\n| word &lt;chr&gt; | dim_1 &lt;dbl&gt; | dim_2 &lt;dbl&gt; | dim_3 &lt;dbl&gt; | dim_4 &lt;dbl&gt; | dim_5 &lt;dbl&gt; | dim_6 &lt;dbl&gt; | dim_7 &lt;dbl&gt; | dim_8 &lt;dbl&gt; | dim_9 &lt;dbl&gt; | ⋯ ⋯ | dim_41 &lt;dbl&gt; | dim_42 &lt;dbl&gt; | dim_43 &lt;dbl&gt; | dim_44 &lt;dbl&gt; | dim_45 &lt;dbl&gt; | dim_46 &lt;dbl&gt; | dim_47 &lt;dbl&gt; | dim_48 &lt;dbl&gt; | dim_49 &lt;dbl&gt; | dim_50 &lt;dbl&gt; |\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n| the | 0.418000 |  0.249680 | -0.41242 |  0.121700 | 0.34527 | -0.044457 | -0.49688 | -0.17862 | -0.00066023 | ⋯ | -2.9871e-01 | -0.157490 | -0.347580 | -0.045637 | -0.44251 | 0.187850 |  0.0027849 | -0.184110 | -0.115140 | -0.78581 |\n| ,   | 0.013441 |  0.236820 | -0.16899 |  0.409510 | 0.63812 |  0.477090 | -0.42852 | -0.55641 | -0.36400000 | ⋯ | -8.0262e-02 |  0.630030 |  0.321110 | -0.467650 |  0.22786 | 0.360340 | -0.3781800 | -0.566570 |  0.044691 |  0.30392 |\n| .   | 0.151640 |  0.301770 | -0.16763 |  0.176840 | 0.31719 |  0.339730 | -0.43478 | -0.31086 | -0.44999000 | ⋯ | -6.3681e-05 |  0.068987 |  0.087939 | -0.102850 | -0.13931 | 0.223140 | -0.0808030 | -0.356520 |  0.016413 |  0.10216 |\n| of  | 0.708530 |  0.570880 | -0.47160 |  0.180480 | 0.54449 |  0.726030 |  0.18157 | -0.52393 |  0.10381000 | ⋯ | -3.4727e-01 |  0.284830 |  0.075693 | -0.062178 | -0.38988 | 0.229020 | -0.2161700 | -0.225620 | -0.093918 | -0.80375 |\n| to  | 0.680470 | -0.039263 |  0.30186 | -0.177920 | 0.42962 |  0.032246 | -0.41376 |  0.13228 | -0.29847000 | ⋯ | -9.4375e-02 |  0.018324 |  0.210480 | -0.030880 | -0.19722 | 0.082279 | -0.0943400 | -0.073297 | -0.064699 | -0.26044 |\n| and | 0.268180 |  0.143460 | -0.27877 |  0.016257 | 0.11384 |  0.699230 | -0.51332 | -0.47368 | -0.33075000 | ⋯ | -6.9043e-02 |  0.368850 |  0.251680 | -0.245170 |  0.25381 | 0.136700 | -0.3117800 | -0.632100 | -0.250280 | -0.38097 |\n\n",
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A tibble: 6 × 51</caption>\n",
              "<thead>\n",
              "\t<tr><th scope=col>word</th><th scope=col>dim_1</th><th scope=col>dim_2</th><th scope=col>dim_3</th><th scope=col>dim_4</th><th scope=col>dim_5</th><th scope=col>dim_6</th><th scope=col>dim_7</th><th scope=col>dim_8</th><th scope=col>dim_9</th><th scope=col>⋯</th><th scope=col>dim_41</th><th scope=col>dim_42</th><th scope=col>dim_43</th><th scope=col>dim_44</th><th scope=col>dim_45</th><th scope=col>dim_46</th><th scope=col>dim_47</th><th scope=col>dim_48</th><th scope=col>dim_49</th><th scope=col>dim_50</th></tr>\n",
              "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>⋯</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><td>the</td><td>0.418000</td><td> 0.249680</td><td>-0.41242</td><td> 0.121700</td><td>0.34527</td><td>-0.044457</td><td>-0.49688</td><td>-0.17862</td><td>-0.00066023</td><td>⋯</td><td>-2.9871e-01</td><td>-0.157490</td><td>-0.347580</td><td>-0.045637</td><td>-0.44251</td><td>0.187850</td><td> 0.0027849</td><td>-0.184110</td><td>-0.115140</td><td>-0.78581</td></tr>\n",
              "\t<tr><td>,  </td><td>0.013441</td><td> 0.236820</td><td>-0.16899</td><td> 0.409510</td><td>0.63812</td><td> 0.477090</td><td>-0.42852</td><td>-0.55641</td><td>-0.36400000</td><td>⋯</td><td>-8.0262e-02</td><td> 0.630030</td><td> 0.321110</td><td>-0.467650</td><td> 0.22786</td><td>0.360340</td><td>-0.3781800</td><td>-0.566570</td><td> 0.044691</td><td> 0.30392</td></tr>\n",
              "\t<tr><td>.  </td><td>0.151640</td><td> 0.301770</td><td>-0.16763</td><td> 0.176840</td><td>0.31719</td><td> 0.339730</td><td>-0.43478</td><td>-0.31086</td><td>-0.44999000</td><td>⋯</td><td>-6.3681e-05</td><td> 0.068987</td><td> 0.087939</td><td>-0.102850</td><td>-0.13931</td><td>0.223140</td><td>-0.0808030</td><td>-0.356520</td><td> 0.016413</td><td> 0.10216</td></tr>\n",
              "\t<tr><td>of </td><td>0.708530</td><td> 0.570880</td><td>-0.47160</td><td> 0.180480</td><td>0.54449</td><td> 0.726030</td><td> 0.18157</td><td>-0.52393</td><td> 0.10381000</td><td>⋯</td><td>-3.4727e-01</td><td> 0.284830</td><td> 0.075693</td><td>-0.062178</td><td>-0.38988</td><td>0.229020</td><td>-0.2161700</td><td>-0.225620</td><td>-0.093918</td><td>-0.80375</td></tr>\n",
              "\t<tr><td>to </td><td>0.680470</td><td>-0.039263</td><td> 0.30186</td><td>-0.177920</td><td>0.42962</td><td> 0.032246</td><td>-0.41376</td><td> 0.13228</td><td>-0.29847000</td><td>⋯</td><td>-9.4375e-02</td><td> 0.018324</td><td> 0.210480</td><td>-0.030880</td><td>-0.19722</td><td>0.082279</td><td>-0.0943400</td><td>-0.073297</td><td>-0.064699</td><td>-0.26044</td></tr>\n",
              "\t<tr><td>and</td><td>0.268180</td><td> 0.143460</td><td>-0.27877</td><td> 0.016257</td><td>0.11384</td><td> 0.699230</td><td>-0.51332</td><td>-0.47368</td><td>-0.33075000</td><td>⋯</td><td>-6.9043e-02</td><td> 0.368850</td><td> 0.251680</td><td>-0.245170</td><td> 0.25381</td><td>0.136700</td><td>-0.3117800</td><td>-0.632100</td><td>-0.250280</td><td>-0.38097</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhSmo7FLylhL"
      },
      "source": [
        "# Convert the ngrams df to vectors \n",
        "# define parameters of Keras model\n",
        "library(keras)\n",
        "max_words = 1e4\n",
        "maxlen = 2\n",
        "dim_size = 50\n",
        "# tokenize the input data and then fit the created object\n",
        "X_seg = text_tokenizer(num_words = max_words ) %>%\n",
        "  fit_text_tokenizer( paste( c(df$X1, df$X2 , df$y ) , sep=\" \") )\n",
        "X_seg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "R-yzuDhsEsg2",
        "outputId": "c586b44e-bec5-44bd-8a74-b2de25c3f30e"
      },
      "source": [
        "# apply tokenizer to the text and get indices instead of words\n",
        "# later pad the sequence\n",
        "Xtrain = texts_to_sequences(X_seg , paste( df$X1, df$X2  , sep=\" \") )  %>%\n",
        " pad_sequences( maxlen = maxlen)\n",
        "tail(Xtrain,3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "          [,1] [,2]\n",
              "[259947,] 0    0   \n",
              "[259948,] 0    2   \n",
              "[259949,] 0    0   "
            ],
            "text/latex": "A matrix: 3 × 2 of type int\n\\begin{tabular}{r|ll}\n\t{[}259947,{]} & 0 & 0\\\\\n\t{[}259948,{]} & 0 & 2\\\\\n\t{[}259949,{]} & 0 & 0\\\\\n\\end{tabular}\n",
            "text/markdown": "\nA matrix: 3 × 2 of type int\n\n| [259947,] | 0 | 0 |\n| [259948,] | 0 | 2 |\n| [259949,] | 0 | 0 |\n\n",
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A matrix: 3 × 2 of type int</caption>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>[259947,]</th><td>0</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>[259948,]</th><td>0</td><td>2</td></tr>\n",
              "\t<tr><th scope=row>[259949,]</th><td>0</td><td>0</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Rv9cHuTrEvv7",
        "outputId": "87b828ca-806e-4de0-c87d-7c032101f9b3"
      },
      "source": [
        "#tokenize Ytrain as well\n",
        "# tokenize the input data and then fit the created object\n",
        "# Y_seg = text_tokenizer(num_words = max_words ) %>%\n",
        "#   fit_text_tokenizer( df$y )\n",
        "# Y_seg\n",
        "# apply tokenizer to the text and get indices instead of words\n",
        "# later pad the sequence\n",
        "Ytrain = texts_to_sequences(X_seg , df$y ) %>%\n",
        " pad_sequences( maxlen = 1)\n",
        " head(Ytrain,3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "     [,1]\n",
              "[1,] 0   \n",
              "[2,] 0   \n",
              "[3,] 0   "
            ],
            "text/latex": "A matrix: 3 × 1 of type int\n\\begin{tabular}{l}\n\t 0\\\\\n\t 0\\\\\n\t 0\\\\\n\\end{tabular}\n",
            "text/markdown": "\nA matrix: 3 × 1 of type int\n\n| 0 |\n| 0 |\n| 0 |\n\n",
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A matrix: 3 × 1 of type int</caption>\n",
              "<tbody>\n",
              "\t<tr><td>0</td></tr>\n",
              "\t<tr><td>0</td></tr>\n",
              "\t<tr><td>0</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "_w-IMZF37TYO",
        "outputId": "012f40ec-eb29-4dc0-a54a-21315c55f837"
      },
      "source": [
        "# Unlist and make dataframe  and join with \n",
        "# downloaded pretrained word Embeddings\n",
        "# unlist word indices\n",
        "word_indices = unlist( X_seg$word_index)\n",
        "# word_indices_Y = unlist(Y_seg$word_index)\n",
        "tail(word_indices,3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "still     t     s \n",
              "   10    11    12 "
            ],
            "text/latex": "\\begin{description*}\n\\item[still] 10\n\\item[t] 11\n\\item[s] 12\n\\end{description*}\n",
            "text/markdown": "still\n:   10t\n:   11s\n:   12\n\n",
            "text/html": [
              "<style>\n",
              ".dl-inline {width: auto; margin:0; padding: 0}\n",
              ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
              ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
              ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
              "</style><dl class=dl-inline><dt>still</dt><dd>10</dd><dt>t</dt><dd>11</dd><dt>s</dt><dd>12</dd></dl>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "netaVZEpFpRV",
        "outputId": "909755ba-8801-4feb-ea9e-ee2c8b3b2711"
      },
      "source": [
        "# then place them into data.frame \n",
        "dic = data.frame(word = names(word_indices) , key = word_indices, stringsAsFactors = FALSE) %>%\n",
        "  arrange(key) %>% .[1:max_words,]\n",
        "dic <- data.frame( word = unique(dic$word))\n",
        "tail(dic)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   word \n",
              "8  stop \n",
              "9  it   \n",
              "10 still\n",
              "11 t    \n",
              "12 s    \n",
              "13 NA   "
            ],
            "text/latex": "A data.frame: 6 × 1\n\\begin{tabular}{r|l}\n  & word\\\\\n  & <chr>\\\\\n\\hline\n\t8 & stop \\\\\n\t9 & it   \\\\\n\t10 & still\\\\\n\t11 & t    \\\\\n\t12 & s    \\\\\n\t13 & NA   \\\\\n\\end{tabular}\n",
            "text/markdown": "\nA data.frame: 6 × 1\n\n| <!--/--> | word &lt;chr&gt; |\n|---|---|\n| 8 | stop  |\n| 9 | it    |\n| 10 | still |\n| 11 | t     |\n| 12 | s     |\n| 13 | NA    |\n\n",
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A data.frame: 6 × 1</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>word</th></tr>\n",
              "\t<tr><th></th><th scope=col>&lt;chr&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>8</th><td>stop </td></tr>\n",
              "\t<tr><th scope=row>9</th><td>it   </td></tr>\n",
              "\t<tr><th scope=row>10</th><td>still</td></tr>\n",
              "\t<tr><th scope=row>11</th><td>t    </td></tr>\n",
              "\t<tr><th scope=row>12</th><td>s    </td></tr>\n",
              "\t<tr><th scope=row>13</th><td>NA   </td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxCQh36IGNOh",
        "outputId": "c536c315-9524-45d0-c87c-caca7a9d9a91"
      },
      "source": [
        "# join the words with GloVe vectors and\n",
        "# if word does not exist in GloVe, then fill NA's with 0\n",
        "word_embeds = dic %>% left_join(vectors) %>% .[,2:51] %>% replace(., is.na(.), 0) %>% as.matrix()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Joining, by = \"word\"\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekiWJpyVnQNB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8ab1f324-44d0-4c66-d880-7e09344e6cd9"
      },
      "source": [
        "dim(word_embeds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] 13 50"
            ],
            "text/latex": "\\begin{enumerate*}\n\\item 13\n\\item 50\n\\end{enumerate*}\n",
            "text/markdown": "1. 13\n2. 50\n\n\n",
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>13</li><li>50</li></ol>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqF-GF8SUA6N"
      },
      "source": [
        "# install.packages(\"sjlabelled\")\n",
        "# library(sjlabelled)\n",
        "# Ytrain <- as_factor(Ytrain)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ly7O7UJVM7M9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 716
        },
        "outputId": "4955cbea-540b-4d6c-d2db-ab77ccdc1ecb"
      },
      "source": [
        "# Use Keras Functional API \n",
        "input = layer_input(shape = list(maxlen), name = \"input\")\n",
        "\n",
        "model = input %>%\n",
        "  layer_embedding(input_dim = max_words, output_dim = dim_size, input_length = maxlen,\n",
        "                  # put weights into list and do not allow training\n",
        "                  weights = list(word_embeds), trainable = FALSE) %>%\n",
        "  \n",
        "  layer_lstm(units = 10 , return_sequences = TRUE )%>%\n",
        "  layer_lstm(units = 5  )\n",
        "\n",
        "  lastLayer = model %>% layer_lstm(units= 1, activation='relu')\n",
        "  \n",
        "output =   lastLayer\n",
        "\n",
        "model = keras_model(input, output)\n",
        "\n",
        "# Compile and fit\n",
        "# instead of accuracy we can use \"AUC\" metrics from \"tensorflow.keras\"\n",
        "model %>% compile(\n",
        "  optimizer = \"adam\",\n",
        "  loss = \"sparse_categorical_crossentropy\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ERROR",
          "evalue": "ignored",
          "traceback": [
            "Error in py_call_impl(callable, dots$args, dots$keywords): ValueError: Layer weight shape (10000, 50) not compatible with provided weight shape (6194, 50)\n\nDetailed traceback:\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 952, in __call__\n    input_list)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 1091, in _functional_construction_call\n    inputs, input_masks, args, kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 822, in _keras_tensor_symbolic_call\n    return self._infer_output_signature(inputs, args, kwargs, input_masks)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 862, in _infer_output_signature\n    self._maybe_build(inputs)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 2722, in _maybe_build\n    self.set_weights(self._initial_weights)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 1873, in set_weights\n    'shape %s' % (ref_shape, weight.shape))\n\nTraceback:\n",
            "1. input %>% layer_embedding(input_dim = max_words, output_dim = dim_size, \n .     input_length = maxlen, weights = list(word_embeds), trainable = FALSE) %>% \n .     layer_lstm(units = 10, return_sequences = TRUE) %>% layer_lstm(units = 5)",
            "2. layer_lstm(., units = 5)",
            "3. create_layer(keras$layers$LSTM, object, args)",
            "4. layer_lstm(., units = 10, return_sequences = TRUE)",
            "5. create_layer(keras$layers$LSTM, object, args)",
            "6. layer_embedding(., input_dim = max_words, output_dim = dim_size, \n .     input_length = maxlen, weights = list(word_embeds), trainable = FALSE)",
            "7. create_layer(keras$layers$Embedding, object, list(input_dim = as.integer(input_dim), \n .     output_dim = as.integer(output_dim), embeddings_initializer = embeddings_initializer, \n .     embeddings_regularizer = embeddings_regularizer, activity_regularizer = activity_regularizer, \n .     embeddings_constraint = embeddings_constraint, mask_zero = mask_zero, \n .     input_length = if (!is.null(input_length)) as.integer(input_length) else NULL, \n .     batch_size = as_nullable_integer(batch_size), name = name, \n .     trainable = trainable, weights = weights))",
            "8. compose_layer(object, layer)",
            "9. compose_layer.python.builtin.object(object, layer)",
            "10. layer(object, ...)",
            "11. py_call_impl(callable, dots$args, dots$keywords)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpMS9eH7V7OD",
        "outputId": "0ea08e33-596f-4beb-a265-a8a3bcc36089"
      },
      "source": [
        "summary(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "________________________________________________________________________________\n",
            "Layer (type)                        Output Shape                    Param #     \n",
            "================================================================================\n",
            "input (InputLayer)                  [(None, 2)]                     0           \n",
            "________________________________________________________________________________\n",
            "embedding_2 (Embedding)             (None, 2, 50)                   500000      \n",
            "________________________________________________________________________________\n",
            "lstm_5 (LSTM)                       (None, 2, 10)                   2440        \n",
            "________________________________________________________________________________\n",
            "lstm_4 (LSTM)                       (None, 5)                       320         \n",
            "________________________________________________________________________________\n",
            "dense_2 (Dense)                     (None, 1)                       6           \n",
            "================================================================================\n",
            "Total params: 502,766\n",
            "Trainable params: 2,766\n",
            "Non-trainable params: 500,000\n",
            "________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_jWXYYwy5W4"
      },
      "source": [
        "fit(model,\n",
        "  Xtrain,\n",
        "   Ytrain,\n",
        "  epochs = 1\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57hFaj04OEOK"
      },
      "source": [
        "evaluate(model,\n",
        "  Xtrain,\n",
        "   Ytrain)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dT0gcgSNX8_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}